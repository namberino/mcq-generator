[page 2] . . 12
2 Xửlý Dữliệu Văn bản . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12


**5** **4. Các kỹthuật nâng cao** **13**
1 Lựa chọn K tối ưu - Elbow Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

2 K-Means++ Initialization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13


**1** **Phần II: Triển khai Thuật toán K-Means từđầu trong Python** **15**
1 Bước 1: Import các thư viện cần thiết . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
2 Bước 2: Đọc và khám phá dữliệu . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
3 Bước 3: Chọn sốcụm và khởi tạo centroids . . . . . . . . . . . . . . . . . . . . . . . . . 16
4 Bước 4: Triển khai thuật toán K-Means chính . . . . . . . . . . . . . . . . . . . . . . . . 17
5 Bước 5: Trực quan hóa kết quả . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17


1

[page 14] ext.fit(bow_matrix.toarray ())`

24 `print` `(` `"Text` `clustering` `labels:"` `, labels)`

## **4. Các kỹthuật nâng cao**


**1** **Lựa chọn K tối ưu - Elbow Method**


1 `def` `elbow_method(X, max_k =10):`

2 `wcss_values = []`

3 `k_range = range` `(1, max_k + 1)`


4


5 `for k in k_range:`

6 `kmeans = KMeans(k=k)`


7 `labels = kmeans.fit(X)`


8 `wcss = calculate_wcss(X, labels, kmeans.centroids)`

9 `wcss_values.append(wcss)`


10


11 `# Plot the Elbow` `graph`

12 `plt.figure(figsize =(10, 6))`

13 `plt.plot(k_range, wcss_values, ’bo -’)`

14 `plt.xlabel(` `’Number of clusters (k)’)`

15 `plt.ylabel(` `’WCSS ’)`

16 `plt.title(` `’Elbow` `Method to select` `optimal k’)`

17 `plt.grid(True)`

18 `plt.show ()`


19


20 `return` `wcss_values`


21


22 `# Use the Elbow` `Method`


23 `wcss_values = elbow_method(X, max_k =8)`


**2** **K-Means++ Initialization**


Cải thiện việc khởi tạo centroids đểtránh local minima:


1 `def` `kmeans_plus_plus_init (X, k):`

2 `centroids = []`


3


4 `# Randomly` `select the first` `centroid`

5 `centroids.append(X[np.random.randint(X.shape [0]) ])`


6


7 `for _ in range` `(1, k):`

8 `# Calculate` `distance to the` `nearest` `centroi

[page 17] **AI VIETNAM** **aivietnam.edu.vn**


12 `plt.ylabel(’Loan` `Amount (Thousands) ’)`

13 `plt.show ()`


Listing 3: Chọn biến và trực quan hóa dữliệu


**3** **Bước 3: Chọn sốcụm và khởi tạo centroids**


Bước 1 và 2 của K-Means là vềviệc chọn sốlượng cụm (k) và chọn các centroids ngẫu nhiên cho mỗi
cụm. Chúng ta sẽchọn 3 cụm và sau đó chọn các quan sát ngẫu nhiên từdữliệu làm centroids:


1 `# Step 1 and 2 - Choose the number of clusters (k) and` `randomly` `select` `centroids` `for`

```
    each cluster

```

2


3 `# number of clusters`


4 `K = 3`


5


6 `# Randomly` `select` `observations as centroids`

7 `Centroids = X.sample(n=K)`

8 `plt.scatter(X[" ApplicantIncome "], X[" LoanAmount "], c=’black ’)`

9 `plt.scatter(Centroids [" ApplicantIncome "], Centroids [" LoanAmount "], c=’red ’)`

10 `plt.xlabel(’Annual Income ’)`

11 `plt.ylabel(’Loan` `Amount (Thousands) ’)`


Listing 4: Chọn sốcụm và khởi tạo centroids


Ởđây, các chấm đỏđại diện cho 3 centroids của mỗi cụm. Lưu ý rằng chúng ta đã chọn những điểm
này một cách ngẫu nhiên, và do đó mỗi lần bạn chạy mã này, bạn có thểnhận được các centroids khác
nhau.


16

[page 4]  =
_|C_ _i_ _|_



� _x_ (1)

_x∈C_ _i_



Trong đó _|C_ _i_ _|_ là sốlượng điểm trong cụm _C_ _i_ . **Cluster Assignment** là việc gán điểm _x_ _j_ vào cụm _C_ _i_ được thực hiện dựa trên nguyên tắc khoảng
cách gần nhất:
label( _x_ _j_ ) = arg min (2)
_i∈{_ 1 _,_ 2 _,...,k}_ _[d]_ [(] _[x]_ _[j]_ _[, µ]_ _[i]_ [)]


Trong đó _d_ ( _x_ _j_ _, µ_ _i_ ) là hàm khoảng cách giữa điểm _x_ _j_ và centroid _µ_ _i_ . **3** **Công thức Toán học**


Cho tập dữliệu _{x_ 1 _, x_ 2 _, . . ., x_ _n_ _}_ với _x_ _i_ _∈_ R _[d]_ . Mục tiêu của K-Means là tìm _k_ cụm _S_ = _{S_ 0 _, S_ 1 _, . . ., S_ _k−_ 1 _}_ đểminimize:



� _∥x −_ _c_ _i_ _∥_ [2] (3)

_x∈S_ _i_



WCSS =



_k−_ 1
�


_i_ =0



Trong đó:


- _c_ _i_ là centroid của cụm _S_ _i_


- _∥x −_ _c_ _i_ _∥_ [2] là khoảng cách Euclidean bình phương


WCSS (Within-Cluster Sum of Squares) là tổng bình phương khoảng cách trong cụm


3

[page 9] **AI VIETNAM** **aivietnam.edu.vn**


và nợcao, trong khi cụm xanh có thu nhập cao nhưng nợthấp. Rõ ràng cụm phân chia trong trường
hợp II hợp lý hơn. Như vậy, các điểm dữliệu từcác cụm khác nhau nên khác biệt nhiều nhất có thểđểtạo thành các
cụm có ý nghĩa hơn. Thuật toán K-means dùng phương pháp lặp đểtìm phân cụm tối ưu bằng cách
giảm thiểu tổng bình phương khoảng cách giữa các điểm và centroid của cụm. **5.3** **Tại sao chúng ta cần phân cụm?**


Chúng ta đã hiểu phân cụm là gì và các thuộc tính khác nhau của cụm. Vậy tại sao phải dùng phân
cụm? Phần tiếp theo sẽgiải đáp thắc mắc này và giới thiệu một sốứng dụng thực tế. **6** **Ứng dụng của phân cụm trong thực tế**


Phân cụm được sửdụng rộng rãi trong nhiều lĩnh vực, từngân hàng, hệthống đềxuất, đến phân cụm
văn bản và phân đoạn ảnh. - **Phân đoạn khách hàng:** Đây là ứng dụng phổbiến nhất của phân cụm, không chỉtrong ngân
hàng mà còn trong viễn thông, thương mại điện tử, thểthao, quảng cáo, bán hàng,... - **Phân cụm văn bản:** Nếu bạn có nhiều tài liệu và muốn nhóm các tài liệu tương tựlại với nhau,
phân cụm giúp gom các tài liệu giống nhau vào cùng một nhóm.