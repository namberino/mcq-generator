{
  "mcqs": {
    "1": {
      "câu hỏi": "Theo chứng minh tính chất 2 (Bịchặn) dựa trên bất đẳng thức Cauchy‑Schwarz, khi nào giá trị K cos(x_j , q) bằng -1?",
      "lựa chọn": {
        "a": "K cos(x_j , q) = -1 nếu x_j và q vuông góc",
        "b": "K cos(x_j , q) = -1 nếu x_j và q cùng hướng",
        "c": "K cos(x_j , q) = -1 nếu x_j và q ngược hướng: x_j = c·q với c < 0",
        "d": "K cos(x_j , q) = -1 nếu x_j = 0 hoặc q = 0"
      },
      "đáp án": "K cos(x_j , q) = -1 nếu x_j và q ngược hướng: x_j = c·q với c < 0"
    },
    "2": {
      "câu hỏi": "Các bước chính trong quy trình xử lý của BERT cho bài toán phân loại tin nhắn spam/ham bao gồm những gì?",
      "lựa chọn": {
        "a": "Mã hóa đầu vào, Tạo embedding từ [MASK] và Đánh giá độ chính xác",
        "b": "Mã hóa đầu vào, Xử lý qua Transformer encoder và Phân loại",
        "c": "Tiền xử lý dữ liệu, Huấn luyện mô hình CNN và Dự đoán nhãn",
        "d": "Phân tách token, Áp dụng TF-IDF và Sử dụng Naive Bayes"
      },
      "đáp án": "Mã hóa đầu vào, Xử lý qua Transformer encoder và Phân loại"
    },
    "3": {
      "câu hỏi": "Trong hệ thống phân loại spam, loại spam nào được mô tả là nguy hiểm nhất, nhằm lừa đảo người dùng cung cấp thông tin cá nhân?",
      "lựa chọn": {
        "a": "Spam khác (Miscellaneous Spam)",
        "b": "Spam hệ thống/lừa đảo (Phishing/System Spam)",
        "c": "Spam quảng cáo",
        "d": "Spam tinh vi (Sophisticated Spam)"
      },
      "đáp án": "Spam hệ thống/lừa đảo (Phishing/System Spam)"
    },
    "4": {
      "câu hỏi": "Trong quy trình phân loại spam/ham được mô tả, vector nào được đưa vào lớp tuyến tính để dự đoán nhãn?",
      "lựa chọn": {
        "a": "Các embedding của từng token trong câu",
        "b": "[CLS] vector",
        "c": "Các trọng số attention",
        "d": "Đầu ra của mạng FFN"
      },
      "đáp án": "[CLS] vector"
    },
    "5": {
      "câu hỏi": "Theo nội dung đã cho, yếu tố nào sau đây được nêu là nhược điểm khi sử dụng mô hình học sâu để tăng cường dataset?",
      "lựa chọn": {
        "a": "Yêu cầu tài nguyên tính toán lớn, thời gian và chi phí cao",
        "b": "Có khả năng hiểu được sự khác biệt tinh tế giữa các cách diễn đạt",
        "c": "Tạo ra các mẫu mới để mở rộng dữ liệu",
        "d": "Kết hợp BERT embeddings với nối từ khóa trong phương pháp bán giám sát"
      },
      "đáp án": "Yêu cầu tài nguyên tính toán lớn, thời gian và chi phí cao"
    },
    "6": {
      "câu hỏi": "Theo nội dung, nhược điểm nào của mô hình được nêu ra?",
      "lựa chọn": {
        "a": "Đòi hỏi tài nguyên tính toán lớn",
        "b": "Tăng cường dữ liệu",
        "c": "Phương pháp semi-supervised",
        "d": "Cải thiện hiệu suất ở k=5"
      },
      "đáp án": "Đòi hỏi tài nguyên tính toán lớn"
    },
    "7": {
      "câu hỏi": "Trong hệ thống phân loại tin nhắn, tham số α có vai trò gì?",
      "lựa chọn": {
        "a": "Điều chỉnh mức độ ưu tiên của điểm saliency so với độ tương đồng tổng thể của tin nhắn.",
        "b": "Xác định ngưỡng cho điểm bỏ phiếu.",
        "c": "Chỉ định loại spam cụ thể.",
        "d": "Đánh giá độ chính xác của mô hình."
      },
      "đáp án": "Điều chỉnh mức độ ưu tiên của điểm saliency so với độ tương đồng tổng thể của tin nhắn."
    },
    "8": {
      "câu hỏi": "Trong hệ thống phân loại spam sử dụng FAISS, chỉ số nào được mô tả là sử dụng phép nhân vô hướng (Inner Product) để cho kết quả tương đương với độ tương đồng cosine?",
      "lựa chọn": {
        "a": "IndexFlatIP",
        "b": "IndexIVFFlat",
        "c": "IndexHNSW",
        "d": "IndexPQ"
      },
      "đáp án": "IndexFlatIP"
    },
    "9": {
      "câu hỏi": "Trong các loại spam được mô tả, loại nào được mô tả là nguy hiểm nhất, nhằm lừa đảo người dùng cung cấp thông tin cá nhân như mật khẩu, mã OTP hoặc thông tin thẻ tín dụng?",
      "lựa chọn": {
        "a": "Spam quảng cáo (Promotional Spam)",
        "b": "Spam hệ thống/lừa đảo (Phishing/System Spam)",
        "c": "Spam khác (Miscellaneous Spam)",
        "d": "Spam không xác định"
      },
      "đáp án": "Spam hệ thống/lừa đảo (Phishing/System Spam)"
    },
    "10": {
      "câu hỏi": "Phương pháp semi-supervised sub-category của spam được mô tả trong nội dung sử dụng kỹ thuật nào để tạo biểu diễn văn bản?",
      "lựa chọn": {
        "a": "Word2Vec",
        "b": "BERT embeddings",
        "c": "TF‑IDF",
        "d": "LSTM"
      },
      "đáp án": "BERT embeddings"
    },
    "11": {
      "câu hỏi": "Theo công thức kết hợp lồi được nêu trong nội dung, trọng số được tính như thế nào khi sử dụng tham số α?",
      "lựa chọn": {
        "a": "(1-α) × w_similarity + α × w_saliency",
        "b": "(1-α) × w_similarity×ICF + α × w_saliency",
        "c": "w_similarity×ICF + w_saliency",
        "d": "α × w_similarity×ICF + (1-α) × w_saliency"
      },
      "đáp án": "(1-α) × w_similarity×ICF + α × w_saliency"
    },
    "12": {
      "câu hỏi": "Theo bảng so sánh, độ chính xác của mô hình cải tiến với k = 1 tăng bao nhiêu phần trăm so với mô hình gốc?",
      "lựa chọn": {
        "a": "4.72%",
        "b": "0.77%",
        "c": "92%",
        "d": "86.96%"
      },
      "đáp án": "4.72%"
    },
    "13": {
      "câu hỏi": "Trong công thức trọng số mới đề xuất cho quá trình voting của KNN, yếu tố nào biểu thị tầm quan trọng tinh tế của từng thực thể?",
      "lựa chọn": {
        "a": "similarity( x_j , q )",
        "b": "ICF( y( x_j ) )",
        "c": "saliency( x_j , q )",
        "d": "α (tham số cân bằng)"
      },
      "đáp án": "saliency( x_j , q )"
    },
    "14": {
      "câu hỏi": "Trong kiến trúc BERT-base, mỗi lớp encoder có bao nhiêu head trong Multi-Head Self-Attention?",
      "lựa chọn": {
        "a": "8 head",
        "b": "12 head",
        "c": "16 head",
        "d": "24 head"
      },
      "đáp án": "12 head"
    },
    "15": {
      "câu hỏi": "Theo nội dung, BERT được huấn luyện trước bằng hai nhiệm vụ nào?",
      "lựa chọn": {
        "a": "Masked Language Modeling và Next Sentence Prediction",
        "b": "Sentiment Analysis và Text Summarization",
        "c": "Machine Translation và Question Answering",
        "d": "Named Entity Recognition và Part-of-Speech Tagging"
      },
      "đáp án": "Masked Language Modeling và Next Sentence Prediction"
    },
    "16": {
      "câu hỏi": "Theo bảng tổng hợp, câu nào thuộc nhóm \"lottery_phrases\"?",
      "lựa chọn": {
        "a": "“Flash sale ends tonight – 30% of all items!”",
        "b": "“You’ve been selected for a loyalty reward.”",
        "c": "“Unusual login detected. Was this you?”",
        "d": "“Act now to secure your spot in the seminar.”"
      },
      "đáp án": "“You’ve been selected for a loyalty reward.”"
    },
    "17": {
      "câu hỏi": "Theo nội dung, một nhược điểm của phương pháp dựa trên từ khóa trong việc phát hiện spam là gì?",
      "lựa chọn": {
        "a": "Có thể xử lý linh hoạt các biến thể từ và lỗi chính tả.",
        "b": "Thiếu linh hoạt, không thể xử lý các biến thể từ và lỗi chính tả.",
        "c": "Hiểu ngữ cảnh, phân biệt đúng từ 'free' trong các câu khác nhau.",
        "d": "Sử dụng embedding ngữ cảnh sâu như BERT để nắm bắt ý nghĩa."
      },
      "đáp án": "Thiếu linh hoạt, không thể xử lý các biến thể từ và lỗi chính tả."
    },
    "18": {
      "câu hỏi": "Theo nội dung trên, một nhược điểm chính của các mô hình ngôn ngữ lớn là gì?",
      "lựa chọn": {
        "a": "Yêu cầu tài nguyên tính toán lớn, bao gồm thời gian và chi phí huấn luyện và fine‑tuning.",
        "b": "Có khả năng giải thích quyết định dự đoán một cách rõ ràng và trực quan.",
        "c": "Có thể học được ranh giới phân biệt tốt hơn khi tăng cường dữ liệu.",
        "d": "Cho phép phân loại nhanh chóng với độ chính xác cao ở k = 1."
      },
      "đáp án": "Yêu cầu tài nguyên tính toán lớn, bao gồm thời gian và chi phí huấn luyện và fine‑tuning."
    },
    "19": {
      "câu hỏi": "Trong phương pháp Weighted KNN được mô tả, yếu tố nào được sử dụng làm trọng số để ưu tiên các láng giềng gần hơn?",
      "lựa chọn": {
        "a": "Độ lệch chuẩn",
        "b": "Điểm tương đồng (similarity score)",
        "c": "Khoảng cách Euclid",
        "d": "Số lượng láng giềng"
      },
      "đáp án": "Điểm tương đồng (similarity score)"
    },
    "20": {
      "câu hỏi": "Trong phương pháp kết hợp điểm ngữ nghĩa BERT và điểm từ khóa để đưa ra quyết định cuối cùng, trọng số được gán cho mỗi loại điểm là bao nhiêu?",
      "lựa chọn": {
        "a": "0.5 BERT và 0.5 từ khóa",
        "b": "0.7 BERT và 0.3 từ khóa",
        "c": "0.6 BERT và 0.4 từ khóa",
        "d": "0.8 BERT và 0.2 từ khóa"
      },
      "đáp án": "0.7 BERT và 0.3 từ khóa"
    }
  },
  "validation": {
    "1": {
      "supported_by_embeddings": true,
      "max_similarity": 0.9192600250244141,
      "evidence": [
        {
          "idx": 41,
          "page": 19,
          "score": 0.7189286947250366,
          "text": "Đối với điểm truy vấn _q_, KNN truyền thống tính toán:\n\n\nˆ\n_y_ = arg max _c_ _i_ _∈C_ _[|{][x]_ _[j]_ _[ ∈N]_ _[K]_ [(] _[q]_ [) :] _[ y]_ [(] _[x]_ _[j]_ [) =] _[ c]_ _[i]_ _[}|]_ (1)\n\n\n**Phân tích Bias:**\nXác suất đểmột K-neighborhood ngẫu nhiên chứa _k_ thực thểtừlớp _c_ _i_ tuân theo phân phối siêu hình\nhọc:\n\n\n19"
        },
        {
          "idx": 8,
          "page": 23,
          "score": 0.7741187810897827,
          "text": "**Chứng minh tính chất 2 (Bịchặn):**\nTheo bất đẳng thức Cauchy-Schwarz:\n\n\n_|x_ _j_ _· q| ≤∥x_ _j_ _∥× ∥q∥_ (29)\n\n\nChia cảhai vếcho _∥x_ _j_ _∥× ∥q∥_ (giảsử _x_ _j_ _, q ̸_ = 0):\n\n\n\n_x_ _j_ _·_ _q_\n���� _∥x_ _j_ _∥× ∥q∥_\n\n\n\n_≤_ 1 (30)\n����\n\n\n\nĐiều này có nghĩa là:\n\n\nDấu bằng xảy ra khi:\n\n\n\n_−_ 1 _≤_ _K_ cos ( _x_ _j_ _, q_ ) _≤_ 1 (31)\n\n\n\n\n - _K_ cos ( _x_ _j_ _, q_ ) = 1 nếu _x_ _j_ và _q_ cùng hướng: _x_ _j_ = _c · q_ với _c >_ 0\n\n\n - _K_ cos ( _x_ _j_ _, q_ ) = _−_ 1 nếu _x_ _j_ và _q_ ngược hướng: _x_ _j_ = _c · q_ với _c <_ 0\n\n\n - _K_ cos ( _x_ _j_ _, q_ ) = 0 nếu _x_ _j_ và _q_ vuông góc: _x_ _j_ _⊥_ _q_\n\n\n**Chứng minh tính chất 3 (Chuẩn hóa - Không đổi với độlớn vector):**\nXét hai vector _x_ _[′]_ _j_ [=] _[ λx]_ _[j]_ [ và] _[ q]_ _[′]_ [ =] _[ µq]_ [ với] _[ λ, µ >]_ [ 0][:]\n\n\n23"
        },
        {
          "idx": 56,
          "page": 24,
          "score": 0.9192600250244141,
          "text": "**6.4.3** **Trọng sốNội dung dựa trên Saliency**\n\n\n**Định nghĩa 3** (Gradient-based Saliency) **.** _Thành phần saliency nắm bắt_ _**tầm quan trọng cụthể**_\n_**theo đầu vào**_ _dựa trên mô hình explainable AI:_\n\n\n_saliency_ ( _x_ _j_ _, q_ ) = _∥∇_ _x_ _j_ _L_ ( _f_ ( _x_ _j_ ) _,_ ˆ _y_ ) _∥_ 2 (38)\n\n\n**6.4.4** **Kết hợp Lồi và Tham sốCân bằng** _α_\n\n\n**Định lý 6.1** (Tính chất Convex Combination) **.** _Tham số_ _α tạo ra_ _**kết hợp lồi**_ _của hai lược đồtrọng_\n_số:_\n\n_weight_ = (1 _−_ _α_ ) _× w_ _similarity×ICF_ + _α × w_ _saliency_ (39)\n\n_Với α ∈_ [0 _,_ 1] _, kết quảnằm trong convex hull của hai thành phần._\n\n\n**6.5** **Phân tích Lý thuyết: Tại sao Công thức này Hợp lý**\n\n\n**6.5.1** **Phân tích Hiệu chỉnh Bias**\n\n\n**Định lý 6.2** (Bias Correction) **.** _Đối với majority voting truyền thống, ảnh hưởng kỳvọng của lớp c_ _i_ _là:_\n\nE[ _Influence_ _traditional_ ( _c_ _i_ )] = _K × P_ ( _c_ _i_ ) = _K ×_ _N_ _[n]_ _[i]_ (40)\n\n\n_Với phương pháp trọng sốcủa chúng ta:_\n\n\nE[ _Influence..."
        }
      ],
      "model_verdict": null
    },
    "2": {
      "supported_by_embeddings": true,
      "max_similarity": 0.7949658036231995,
      "evidence": [
        {
          "idx": 21,
          "page": 15,
          "score": 0.5949141979217529,
          "text": "Trong bài toán spam/ham, BERT được tinh\nchỉnh đểtối ưu hóa dựđoán nhãn và tập trung vào các từkhóa quan trọng như “miễn phí” hoặc “quà\ntặng” trong tin nhắn spam. **Ứng dụng** : Trong phân loại tin nhắn spam/ham, BERT chuyển tin nhắn thành vector số, hiểu ngữ\ncảnh sâu sắc (ví dụ: nhận diện ”miễn phí” trong ngữcảnh quảng cáo), và dựđoán nhãn (spam hoặc\nham). **Ưu điểm** :\n\n\n  - Hiểu ngữcảnh hai chiều, vượt trội so với các phương pháp truyền thống như TF-IDF. - Sửdụng vector [CLS] đểtổng hợp thông tin toàn câu, phù hợp cho phân loại. **5.3** **Kiến trúc BERT**\n\n\nQuy trình xửlý của BERT bao gồm ba giai đoạn chính:\n\n\n1. **Mã hóa đầu vào** : Chuyển tin nhắn thành token, embedding, và attention mask. 2. **Xửlý qua Transformer encoder** : Tạo biểu diễn ngữcảnh cho từng token, đặc biệt là vector\n\n[CLS]. 3. **Phân loại** : Sửdụng vector [CLS] đểdựđoán nhãn spam/ham. Phần này trình bày chi tiết từng thành phần của kiến trúc BERT và cách chúng hỗtrợbài toán phân\nloại tin nhắn spam/ham. **5.3.1** *..."
        },
        {
          "idx": 52,
          "page": 11,
          "score": 0.7382397651672363,
          "text": "**AI VIETNAM** **aivietnam.edu.vn**\n\n\n - 2039 mẫu _hard spam_ : được tạo ra đểtăng sốlượng và độphức tạp của các tin nhắn spam, giúp\nmô hình nhận diện tốt hơn các biến thểcủa spam. - 815 mẫu _hard ham_ : là những tin nhắn hợp lệnhưng có chứa từkhóa gần giống spam, buộc mô\nhình phải học cách phân biệt tinh vi hơn giữa hai lớp. - 1053 mẫu được sinh ra bằng kỹthuật _synonym replacement_ (thay thếtừđồng nghĩa), giúp tăng\nsựđa dạng vềmặt ngôn ngữcho cảhai lớp. Kết quảlà một dataset dùng đểphân loại có kích thước 9479 mẫu gồm 6556 mẫu Ham, 2923 mẫu Spam\ncó phân phối cân bằng hơn, tạo nền tảng vững chắc cho việc huấn luyện mô hình phân loại hiệu quả. **Phương pháp**\n\n\nĐểđạt được mục tiêu trên, nhóm mình đã thiết kếmột hệthống data augmentation chuyên biệt, kết\nhợp giữa kỹthuật sinh dữliệu bằng mô hình ngôn ngữlớn (LLM), thay thếtừđồng nghĩa, và khung\nsinh câu theo kịch bản có kiểm soát. Hệthống gồm ba giai đoạn chính:\n\n\n1."
        },
        {
          "idx": 64,
          "page": 27,
          "score": 0.7949658036231995,
          "text": "**AI VIETNAM** **aivietnam.edu.vn**\n\n## **7 Semi-supervised đểphân loại sub-category của spam**\n\n\n**7.1** **Vấn đề”Spam” không chỉlà ”Spam”**\n\n\nKhi đối mặt với vấn đềspam, việc phân loại nhịphân (binary classification) thành hai loại ”spam” và\n”không spam” (ham) là chưa đủđểxây dựng một hệthống phòng chống hiệu quả. Bản chất của tin\nnhắn spam đã thay đổi và trởnên đa dạng hơn rất nhiều. Việc coi tất cảcác tin nhắn spam như nhau sẽ\nbỏqua những sắc thái quan trọng, dẫn đến việc chúng ta không thểđưa ra các biện pháp xửlý phù hợp. Khi phân tích sâu hơn, chúng ta thấy rằng spam có thểđược chia thành nhiều **thểloại con (sub-**\n**category) khác nhau**, mỗi loại có mục tiêu và phương thức hoạt động riêng biệt:\n\n\n **Spam quảng cáo** (Promotional Spam): Nhằm mục đích tiếp thịsản phẩm, dịch vụ, các chương\ntrình khuyến mãi, giảm giá, hoặc các thông báo trúng thưởng. Đặc điểm của loại này là thường\nchứa các từkhóa liên quan đến mua sắm, giá cả, ưu đãi..."
        }
      ],
      "model_verdict": null
    },
    "3": {
      "supported_by_embeddings": true,
      "max_similarity": 0.5782788991928101,
      "evidence": [
        {
          "idx": 52,
          "page": 11,
          "score": 0.5782788991928101,
          "text": "**AI VIETNAM** **aivietnam.edu.vn**\n\n\n - 2039 mẫu _hard spam_ : được tạo ra đểtăng sốlượng và độphức tạp của các tin nhắn spam, giúp\nmô hình nhận diện tốt hơn các biến thểcủa spam. - 815 mẫu _hard ham_ : là những tin nhắn hợp lệnhưng có chứa từkhóa gần giống spam, buộc mô\nhình phải học cách phân biệt tinh vi hơn giữa hai lớp. - 1053 mẫu được sinh ra bằng kỹthuật _synonym replacement_ (thay thếtừđồng nghĩa), giúp tăng\nsựđa dạng vềmặt ngôn ngữcho cảhai lớp. Kết quảlà một dataset dùng đểphân loại có kích thước 9479 mẫu gồm 6556 mẫu Ham, 2923 mẫu Spam\ncó phân phối cân bằng hơn, tạo nền tảng vững chắc cho việc huấn luyện mô hình phân loại hiệu quả. **Phương pháp**\n\n\nĐểđạt được mục tiêu trên, nhóm mình đã thiết kếmột hệthống data augmentation chuyên biệt, kết\nhợp giữa kỹthuật sinh dữliệu bằng mô hình ngôn ngữlớn (LLM), thay thếtừđồng nghĩa, và khung\nsinh câu theo kịch bản có kiểm soát. Hệthống gồm ba giai đoạn chính:\n\n\n1."
        }
      ],
      "model_verdict": null
    },
    "4": {
      "supported_by_embeddings": true,
      "max_similarity": 0.7534276247024536,
      "evidence": [
        {
          "idx": 21,
          "page": 15,
          "score": 0.7180466651916504,
          "text": "Trong bài toán spam/ham, BERT được tinh\nchỉnh đểtối ưu hóa dựđoán nhãn và tập trung vào các từkhóa quan trọng như “miễn phí” hoặc “quà\ntặng” trong tin nhắn spam. **Ứng dụng** : Trong phân loại tin nhắn spam/ham, BERT chuyển tin nhắn thành vector số, hiểu ngữ\ncảnh sâu sắc (ví dụ: nhận diện ”miễn phí” trong ngữcảnh quảng cáo), và dựđoán nhãn (spam hoặc\nham). **Ưu điểm** :\n\n\n  - Hiểu ngữcảnh hai chiều, vượt trội so với các phương pháp truyền thống như TF-IDF. - Sửdụng vector [CLS] đểtổng hợp thông tin toàn câu, phù hợp cho phân loại. **5.3** **Kiến trúc BERT**\n\n\nQuy trình xửlý của BERT bao gồm ba giai đoạn chính:\n\n\n1. **Mã hóa đầu vào** : Chuyển tin nhắn thành token, embedding, và attention mask. 2. **Xửlý qua Transformer encoder** : Tạo biểu diễn ngữcảnh cho từng token, đặc biệt là vector\n\n[CLS]. 3. **Phân loại** : Sửdụng vector [CLS] đểdựđoán nhãn spam/ham. Phần này trình bày chi tiết từng thành phần của kiến trúc BERT và cách chúng hỗtrợbài toán phân\nloại tin nhắn spam/ham. **5.3.1** *..."
        },
        {
          "idx": 64,
          "page": 27,
          "score": 0.7191596031188965,
          "text": "**AI VIETNAM** **aivietnam.edu.vn**\n\n## **7 Semi-supervised đểphân loại sub-category của spam**\n\n\n**7.1** **Vấn đề”Spam” không chỉlà ”Spam”**\n\n\nKhi đối mặt với vấn đềspam, việc phân loại nhịphân (binary classification) thành hai loại ”spam” và\n”không spam” (ham) là chưa đủđểxây dựng một hệthống phòng chống hiệu quả. Bản chất của tin\nnhắn spam đã thay đổi và trởnên đa dạng hơn rất nhiều. Việc coi tất cảcác tin nhắn spam như nhau sẽ\nbỏqua những sắc thái quan trọng, dẫn đến việc chúng ta không thểđưa ra các biện pháp xửlý phù hợp. Khi phân tích sâu hơn, chúng ta thấy rằng spam có thểđược chia thành nhiều **thểloại con (sub-**\n**category) khác nhau**, mỗi loại có mục tiêu và phương thức hoạt động riêng biệt:\n\n\n **Spam quảng cáo** (Promotional Spam): Nhằm mục đích tiếp thịsản phẩm, dịch vụ, các chương\ntrình khuyến mãi, giảm giá, hoặc các thông báo trúng thưởng. Đặc điểm của loại này là thường\nchứa các từkhóa liên quan đến mua sắm, giá cả, ưu đãi..."
        },
        {
          "idx": 1,
          "page": 5,
          "score": 0.7534276247024536,
          "text": "Điều này đặc biệt quan trọng\ntrong các hệthống chống spam hiện đại, giúp người dùng hiểu rõ liệu một email nên bịxóa, xem qua\nhay báo cáo. Ngoài ra, nhóm còn hướng đến việc **mởrộng phân loại chi tiết trong nhóm spam**\n(quảng cáo, hệthống, lừa đảo, v.v...) nhằm tăng trải nghiệm và bảo mật cho người dùng. Hệthống phân loại tin nhắn spam/ham được thiết kếvới cơ chếđầu vào – đầu ra như sau:\n\n\n\n\n\n5"
        }
      ],
      "model_verdict": null
    },
    "5": {
      "supported_by_embeddings": true,
      "max_similarity": 0.7267791032791138,
      "evidence": [
        {
          "idx": 60,
          "page": 10,
          "score": 0.6037057638168335,
          "text": "Đểgiải quyết vấn đềnày, dataset đã được tăng cường đáng kểbằng cách sửdụng một mô hình học sâu\nđểtạo ra các mẫu mới:\n\n\n10"
        },
        {
          "idx": 3,
          "page": 28,
          "score": 0.7101945281028748,
          "text": "**–**\nNhờđó, mô hình có thểhiểu được sựkhác biệt tinh tếgiữa các cách diễn đạt, xửlý được\ncác từđồng nghĩa và các biến thểngôn ngữ. **Nhược điểm:**\n\n\n**– Đòi hỏi tài nguyên tính toán lớn:** Việc huấn luyện và fine-tuning các mô hình này cần\nnhiều thời gian và chi phí. **– Phức tạp:** Việc fine-tuning cho từng tác vụcụthểcó thểphức tạp. Đặc biệt, nếu không có\nđủdữliệu đã được gán nhãn, hiệu quảcủa các mô hình này sẽbịhạn chế. **7.3** **Phương pháp Semi-supervised sub-category của spam**\n\n\nĐểtận dụng ưu điểm của 2 phương pháp phân loại sub-category phần trên. Chúng tôi đềxuất thực\nhiện một phương pháp semi-supervised bằng cách kết hợp bert embeđings với nối từkhóa. Phương pháp này được gọi là ”bán giám sát” vì nó sửdụng một lượng nhỏdữliệu có nhãn (reference_texts\nvà category_keywords) đểphân loại một lượng lớn dữliệu chưa có nhãn (spam_texts). Tiến trình thực hiện của phương pháp như sau:\n\n\n1. **Bước 1: BERT embeddings**\n\n\n  **Tạo Embeddings của Văn bản Spam:** đểbiến mỗi tin nhắn spam ..."
        },
        {
          "idx": 61,
          "page": 26,
          "score": 0.7267791032791138,
          "text": "Những cải thiện này đến từcác yếu tốsau:\n\n\n **Tăng cường dữliệu:** sinh thêm mẫu khó và thay từđồng nghĩa giúp đa dạng hóa ngữcảnh và\nlàm mô hình học được ranh giới phân biệt tốt hơn. **Tập huấn luyện lớn hơn:** từdưới 1.000 mẫu lên hơn 9.000 mẫu giúp mô hình tổng quát hóa\ntốt hơn. **Tập trung vào mẫu khó:** ưu tiên những ví dụgần ranh giới giữa spam/ham nhằm tăng tính\nphân biệt cho mô hình. **Kết luận:** Mô hình mới không chỉđạt hiệu suất cao ở _k_ = 5 mà còn cải thiện đáng kểở _k_ = 1, rất hữu\ních cho các ứng dụng yêu cầu tốc độsuy luận nhanh mà vẫn đảm bảo độchính xác cao. 26"
        }
      ],
      "model_verdict": null
    },
    "6": {
      "supported_by_embeddings": true,
      "max_similarity": 1.1316804885864258,
      "evidence": [
        {
          "idx": 3,
          "page": 28,
          "score": 0.8143035769462585,
          "text": "**–**\nNhờđó, mô hình có thểhiểu được sựkhác biệt tinh tếgiữa các cách diễn đạt, xửlý được\ncác từđồng nghĩa và các biến thểngôn ngữ. **Nhược điểm:**\n\n\n**– Đòi hỏi tài nguyên tính toán lớn:** Việc huấn luyện và fine-tuning các mô hình này cần\nnhiều thời gian và chi phí. **– Phức tạp:** Việc fine-tuning cho từng tác vụcụthểcó thểphức tạp. Đặc biệt, nếu không có\nđủdữliệu đã được gán nhãn, hiệu quảcủa các mô hình này sẽbịhạn chế. **7.3** **Phương pháp Semi-supervised sub-category của spam**\n\n\nĐểtận dụng ưu điểm của 2 phương pháp phân loại sub-category phần trên. Chúng tôi đềxuất thực\nhiện một phương pháp semi-supervised bằng cách kết hợp bert embeđings với nối từkhóa. Phương pháp này được gọi là ”bán giám sát” vì nó sửdụng một lượng nhỏdữliệu có nhãn (reference_texts\nvà category_keywords) đểphân loại một lượng lớn dữliệu chưa có nhãn (spam_texts). Tiến trình thực hiện của phương pháp như sau:\n\n\n1. **Bước 1: BERT embeddings**\n\n\n  **Tạo Embeddings của Văn bản Spam:** đểbiến mỗi tin nhắn spam ..."
        },
        {
          "idx": 61,
          "page": 26,
          "score": 0.9040168523788452,
          "text": "Những cải thiện này đến từcác yếu tốsau:\n\n\n **Tăng cường dữliệu:** sinh thêm mẫu khó và thay từđồng nghĩa giúp đa dạng hóa ngữcảnh và\nlàm mô hình học được ranh giới phân biệt tốt hơn. **Tập huấn luyện lớn hơn:** từdưới 1.000 mẫu lên hơn 9.000 mẫu giúp mô hình tổng quát hóa\ntốt hơn. **Tập trung vào mẫu khó:** ưu tiên những ví dụgần ranh giới giữa spam/ham nhằm tăng tính\nphân biệt cho mô hình. **Kết luận:** Mô hình mới không chỉđạt hiệu suất cao ở _k_ = 5 mà còn cải thiện đáng kểở _k_ = 1, rất hữu\ních cho các ứng dụng yêu cầu tốc độsuy luận nhanh mà vẫn đảm bảo độchính xác cao. 26"
        },
        {
          "idx": 60,
          "page": 10,
          "score": 1.1316804885864258,
          "text": "Đểgiải quyết vấn đềnày, dataset đã được tăng cường đáng kểbằng cách sửdụng một mô hình học sâu\nđểtạo ra các mẫu mới:\n\n\n10"
        }
      ],
      "model_verdict": null
    },
    "7": {
      "supported_by_embeddings": true,
      "max_similarity": 0.9357913732528687,
      "evidence": [
        {
          "idx": 18,
          "page": 7,
          "score": 0.7424218058586121,
          "text": "Tham số _α_ là tham sốđiều chỉnh, quyết định mức độưu tiên của điểm saliency so với độ\ntương đồng tổng thểcủa tin nhắn. - **Vote Scores:** Hệthống hiển thịđiểm sốbỏphiếu cho mỗi lớp ( _Ham_ và _Spam_ ). Dựđoán cuối\ncùng sẽlà lớp có điểm sốcao nhất. - **Spam Subcategory:** Nếu tin nhắn được phân loại là _SPAM_, hệthống tiếp tục phân tích đểxác\nđịnh tiểu mục spam cụthể(ví dụ: _spam_quangcao_, _spam_hethong_ ). **Cơ sởgiải thích (Top neighbors):** Hệthống liệt kê một sốhàng xóm gần nhất trong cơ sởdữ\nliệu vector. Mỗi neighbors bao gồm:\n\n\n**–** _Nhãn (Label):_ Nhãn của tin nhắn gốc ( _ham_ hoặc _spam_ ). **–**\n_Độtương đồng (Similarity):_ Giá trịthểhiện mức độtương đồng giữa tin nhắn đầu vào và\nhàng xóm. **–**\n_Nội dung (Message):_ Nội dung của tin nhắn hàng xóm. 7"
        },
        {
          "idx": 11,
          "page": 29,
          "score": 0.909127414226532,
          "text": "**AI VIETNAM** **aivietnam.edu.vn**\n\n\n  **Tính Độtương đồng Ngữnghĩa:** Đối với mỗi tin nhắn spam, thuật toán tính toán độ\ntương đồng cosine giữa embedding của tin nhắn đó và embedding của từng điểm neo tham\nchiếu. Kết quảlà một điểm số( _bert_scores_ ) cho thấy mức độliên quan vềmặt ngữnghĩa\ncủa tin nhắn với từng tiểu thểloại. 2. **Bước 2: Keyword matching**\n\n\n  **Định nghĩa Từkhóa:** tạo một danh sách từkhóa chi tiết cho từng thểloại con. - **Tính Điểm Từkhóa:** Với mỗi tin nhắn, đoạn mã sẽđếm sốlượng từkhóa trong danh sách\nxuất hiện. Điểm sốnày được chuẩn hóa.( _keyword_scores_ ) đểso sánh công bằng giữa các thể\nloại con có sốlượng từkhóa khác nhau. 3. **Bước 3: combine và ra quyết định** Đây là bước then chốt của phương pháp lai này. **Kết hợp có trọng số:** Mô hình kết hợp hai điểm sốtrên bằng cách sửdụng trọng số. Với\nđiểm ngữnghĩa của BERT chiếm 70% và điểm từkhóa chiếm 30% (0 _._ 7 _×_ bert_scores +0 _._ 3 _×_\nkeyword_scores). Sựkết hợp này tận dụng khảnăng hiểu ngữnghĩa sâu củ..."
        },
        {
          "idx": 68,
          "page": 13,
          "score": 0.9357913732528687,
          "text": "Trong trường hợp này, phép nhân vô hướng (Inner Product) mà\nIndexFlatIP sửdụng sẽcho kết quảtương đương với độtương đồng cosine. Độtương đồng cosine\nlà thước đo tiêu chuẩn đểđánh giá sựtương đồng ngữnghĩa trong các bài toán NLP. Do đó,\nIndexFlatIP là lựa chọn hoàn hảo đểtruy vấn các tin nhắn có ý nghĩa tương tự, tạo ra một hệ\nthống tìm kiếm ngữnghĩa hiệu quảvà chính xác. ## **4 Explainable AI: Masking-based saliency heat map**\n\n\nNhận thấy rằng toàn bộhệthống phân loại sửdụng mô hình embedding E5 kết hợp với cơ sởdữliệu\nFAISS đểtruy vấn và tìm kiếm `k` tin nhắn gần nhất là một mô hình dạng “hộp đen” (black-box), nên\nnhóm đặt mục tiêu tăng tính giải thích của mô hình bằng cách chỉra cụthểnhững token nào trong\ncâu đầu vào thực sựảnh hưởng đến embedding câu, từđó dẫn đến quyết định phân loại. Ý tưởng cụ\nthểlà trực quan hóa mức độđóng góp của từng token bằng bản đồnhiệt (heatmap) — token nào càng\nđóng góp nhiều thì sẽđược tô màu đậm hơn. Do nhóm tập trung chủyếu vào việc phân loại và giải t..."
        }
      ],
      "model_verdict": null
    },
    "8": {
      "supported_by_embeddings": true,
      "max_similarity": 0.610893189907074,
      "evidence": [
        {
          "idx": 1,
          "page": 5,
          "score": 0.5394615530967712,
          "text": "Điều này đặc biệt quan trọng\ntrong các hệthống chống spam hiện đại, giúp người dùng hiểu rõ liệu một email nên bịxóa, xem qua\nhay báo cáo. Ngoài ra, nhóm còn hướng đến việc **mởrộng phân loại chi tiết trong nhóm spam**\n(quảng cáo, hệthống, lừa đảo, v.v...) nhằm tăng trải nghiệm và bảo mật cho người dùng. Hệthống phân loại tin nhắn spam/ham được thiết kếvới cơ chếđầu vào – đầu ra như sau:\n\n\n\n\n\n5"
        },
        {
          "idx": 64,
          "page": 27,
          "score": 0.5891628265380859,
          "text": "**AI VIETNAM** **aivietnam.edu.vn**\n\n## **7 Semi-supervised đểphân loại sub-category của spam**\n\n\n**7.1** **Vấn đề”Spam” không chỉlà ”Spam”**\n\n\nKhi đối mặt với vấn đềspam, việc phân loại nhịphân (binary classification) thành hai loại ”spam” và\n”không spam” (ham) là chưa đủđểxây dựng một hệthống phòng chống hiệu quả. Bản chất của tin\nnhắn spam đã thay đổi và trởnên đa dạng hơn rất nhiều. Việc coi tất cảcác tin nhắn spam như nhau sẽ\nbỏqua những sắc thái quan trọng, dẫn đến việc chúng ta không thểđưa ra các biện pháp xửlý phù hợp. Khi phân tích sâu hơn, chúng ta thấy rằng spam có thểđược chia thành nhiều **thểloại con (sub-**\n**category) khác nhau**, mỗi loại có mục tiêu và phương thức hoạt động riêng biệt:\n\n\n **Spam quảng cáo** (Promotional Spam): Nhằm mục đích tiếp thịsản phẩm, dịch vụ, các chương\ntrình khuyến mãi, giảm giá, hoặc các thông báo trúng thưởng. Đặc điểm của loại này là thường\nchứa các từkhóa liên quan đến mua sắm, giá cả, ưu đãi..."
        },
        {
          "idx": 52,
          "page": 11,
          "score": 0.610893189907074,
          "text": "**AI VIETNAM** **aivietnam.edu.vn**\n\n\n - 2039 mẫu _hard spam_ : được tạo ra đểtăng sốlượng và độphức tạp của các tin nhắn spam, giúp\nmô hình nhận diện tốt hơn các biến thểcủa spam. - 815 mẫu _hard ham_ : là những tin nhắn hợp lệnhưng có chứa từkhóa gần giống spam, buộc mô\nhình phải học cách phân biệt tinh vi hơn giữa hai lớp. - 1053 mẫu được sinh ra bằng kỹthuật _synonym replacement_ (thay thếtừđồng nghĩa), giúp tăng\nsựđa dạng vềmặt ngôn ngữcho cảhai lớp. Kết quảlà một dataset dùng đểphân loại có kích thước 9479 mẫu gồm 6556 mẫu Ham, 2923 mẫu Spam\ncó phân phối cân bằng hơn, tạo nền tảng vững chắc cho việc huấn luyện mô hình phân loại hiệu quả. **Phương pháp**\n\n\nĐểđạt được mục tiêu trên, nhóm mình đã thiết kếmột hệthống data augmentation chuyên biệt, kết\nhợp giữa kỹthuật sinh dữliệu bằng mô hình ngôn ngữlớn (LLM), thay thếtừđồng nghĩa, và khung\nsinh câu theo kịch bản có kiểm soát. Hệthống gồm ba giai đoạn chính:\n\n\n1."
        }
      ],
      "model_verdict": null
    },
    "9": {
      "supported_by_embeddings": true,
      "max_similarity": 0.5543808341026306,
      "evidence": [
        {
          "idx": 39,
          "page": 4,
          "score": 0.5543808341026306,
          "text": "**AI VIETNAM** **aivietnam.edu.vn**\n\n\n\n\n\n**Các lĩnh vực dễbịnhầm lẫn giữa spam và ham**\n\n\nTrong những năm gần đây, sựphát triển của công nghệemail marketing và các hình thức lừa đảo trực\ntuyến đã dẫn đến sựgia tăng mạnh mẽcủa các loại **spam tinh vi** – những tin nhắn rác được _thiết kế_\n_cẩn thận đểvượt qua các bộlọc tựđộng_ . Chúng thường sửdụng ngôn ngữlịch sự, cú pháp tựnhiên như\nemail thật, thậm chí mô phỏng cách viết của email công việc hoặc cá nhân. Cùng lúc đó, cũng tồn tại nhiều email hợp lệ( **ham** ) có chứa các từkhóa như _“transfer”_, _“discount”_,\n_“verify”_ vốn thường xuất hiện trong spam, khiến hệthống nhầm lẫn. Những trường hợp như vậy được\ngọi là **hard ham** – tức là các email hợp pháp nhưng có đặc điểm giống với spam. Vì vậy, các mô hình học máy nếu chỉdựa vào keyword hoặc kỹthuật phân loại đơn giản như TF-IDF,\nNaive Bayes,... sẽkhó đạt hiệu quảcao. Thay vào đó, mô hình cần có khảnăng **hiểu sâu ngữnghĩa**,\nkết hợp thông tin ngữcảnh, cú pháp, và thậm chí cảlịch sửng..."
        }
      ],
      "model_verdict": null
    },
    "10": {
      "supported_by_embeddings": true,
      "max_similarity": 0.5062772035598755,
      "evidence": [
        {
          "idx": 64,
          "page": 27,
          "score": 0.5062772035598755,
          "text": "**AI VIETNAM** **aivietnam.edu.vn**\n\n## **7 Semi-supervised đểphân loại sub-category của spam**\n\n\n**7.1** **Vấn đề”Spam” không chỉlà ”Spam”**\n\n\nKhi đối mặt với vấn đềspam, việc phân loại nhịphân (binary classification) thành hai loại ”spam” và\n”không spam” (ham) là chưa đủđểxây dựng một hệthống phòng chống hiệu quả. Bản chất của tin\nnhắn spam đã thay đổi và trởnên đa dạng hơn rất nhiều. Việc coi tất cảcác tin nhắn spam như nhau sẽ\nbỏqua những sắc thái quan trọng, dẫn đến việc chúng ta không thểđưa ra các biện pháp xửlý phù hợp. Khi phân tích sâu hơn, chúng ta thấy rằng spam có thểđược chia thành nhiều **thểloại con (sub-**\n**category) khác nhau**, mỗi loại có mục tiêu và phương thức hoạt động riêng biệt:\n\n\n **Spam quảng cáo** (Promotional Spam): Nhằm mục đích tiếp thịsản phẩm, dịch vụ, các chương\ntrình khuyến mãi, giảm giá, hoặc các thông báo trúng thưởng. Đặc điểm của loại này là thường\nchứa các từkhóa liên quan đến mua sắm, giá cả, ưu đãi..."
        }
      ],
      "model_verdict": null
    },
    "11": {
      "supported_by_embeddings": true,
      "max_similarity": 0.7763429880142212,
      "evidence": [
        {
          "idx": 14,
          "page": 20,
          "score": 0.7428227663040161,
          "text": "**6.1** **Khung Phân loại Trọng sốĐềxuất**\n\n\nVì vậy nhóm đã nghiên cứu và đềxuất áp dụng công thức trọng sốmới trong quá trình voting của KNN\nbằng kết hợp hai yếu tốtương đồng (similarity) và tầm quan trọng tinh tếcủa từng thực thể(saliency). **6.2** **Công thức Cốt lõi**\n\n\nweight( _x_ _j_ _,_ _q_ ) = (1 _−_ _α_ ) _×_ similarity( _x_ _j_ _,_ _q_ ) _×_ ICF( _y_ ( _x_ _j_ )) + _α ×_ saliency( _x_ _j_ _,_ _q_ ) (5)\n\n\nTrong đó:\n\n\n_x_ _j_ _·_ _q_\nsimilarity( _x_ _j_ _, q_ ) = cos( _x_ _j_ _, q_ ) = (6)\n_∥x_ _j_ _∥× ∥q∥_\n\n\n\n_N_\nICF( _c_ _i_ ) =\n_M × n_ _i_\n\n\n\n(7)\n\n\n\nsaliency( _x_ _j_ _, q_ ) = _∥∇_ _x_ _j_ _L_ ( _f_ ( _x_ _j_ ) _,_ ˆ _y_ ) _∥_ 2 (8)\n\n_α ∈_ [0 _,_ 1] (tham sốcân bằng) (9)\n\n\n**6.3** **Quyết định Phân loại Cuối cùng**\n\n\n\nˆ\n_y_ = arg max\n_c_ _i_ _∈C_\n\n\n\n�\n\n_x_ _j_ _∈N_ _K_ ( _q_ )\n_y_ ( _x_ _j_ )= _c_ _i_\n\n\n20\n\n\n\nweight( _x_ _j_ _, q_ ) (10)"
        },
        {
          "idx": 56,
          "page": 24,
          "score": 0.7464016675949097,
          "text": "**6.4.3** **Trọng sốNội dung dựa trên Saliency**\n\n\n**Định nghĩa 3** (Gradient-based Saliency) **.** _Thành phần saliency nắm bắt_ _**tầm quan trọng cụthể**_\n_**theo đầu vào**_ _dựa trên mô hình explainable AI:_\n\n\n_saliency_ ( _x_ _j_ _, q_ ) = _∥∇_ _x_ _j_ _L_ ( _f_ ( _x_ _j_ ) _,_ ˆ _y_ ) _∥_ 2 (38)\n\n\n**6.4.4** **Kết hợp Lồi và Tham sốCân bằng** _α_\n\n\n**Định lý 6.1** (Tính chất Convex Combination) **.** _Tham số_ _α tạo ra_ _**kết hợp lồi**_ _của hai lược đồtrọng_\n_số:_\n\n_weight_ = (1 _−_ _α_ ) _× w_ _similarity×ICF_ + _α × w_ _saliency_ (39)\n\n_Với α ∈_ [0 _,_ 1] _, kết quảnằm trong convex hull của hai thành phần._\n\n\n**6.5** **Phân tích Lý thuyết: Tại sao Công thức này Hợp lý**\n\n\n**6.5.1** **Phân tích Hiệu chỉnh Bias**\n\n\n**Định lý 6.2** (Bias Correction) **.** _Đối với majority voting truyền thống, ảnh hưởng kỳvọng của lớp c_ _i_ _là:_\n\nE[ _Influence_ _traditional_ ( _c_ _i_ )] = _K × P_ ( _c_ _i_ ) = _K ×_ _N_ _[n]_ _[i]_ (40)\n\n\n_Với phương pháp trọng sốcủa chúng ta:_\n\n\nE[ _Influence..."
        },
        {
          "idx": 48,
          "page": 24,
          "score": 0.7763429880142212,
          "text": "]_ (43)\n\n_M_ _[×]_ [ E][[] _[similarity][ ×][ saliency]_ []]\n\n\n24"
        }
      ],
      "model_verdict": null
    },
    "12": {
      "supported_by_embeddings": true,
      "max_similarity": 0.8878604173660278,
      "evidence": [
        {
          "idx": 47,
          "page": 26,
          "score": 0.7113279104232788,
          "text": "**AI VIETNAM** **aivietnam.edu.vn**\n\n## **Đánh giá và So sánh Mô hình**\n\n\n**Kết quảmô hình gốc (do TA cung cấp)**\n\n\nChúng tôi tiến hành đánh giá mô hình phân loại KNN ban đầu trên tập kiểm tra gồm 884 mẫu, với các\ngiá trị _k_ khác nhau. Kết quảđộchính xác như sau:\n\n|Giá trị k|Độ chính xác|Số mẫu lỗi|\n|---|---|---|\n|1<br>3<br>5|82.24%<br>88.91%<br>92.87%|157/884<br>98/884<br>63/884|\n\n\n\nBảng 3: Hiệu suất mô hình gốc trên tập kiểm tra\n\n\n**Kết quảmô hình cải tiến (do nhóm phát triển)**\n\n\nVới mô hình cải tiến, chúng tôi đã huấn luyện trên một tập dữliệu lớn hơn rất nhiều (9.400 mẫu), được\ntăng cường từtập dữliệu GDrive gốc thông qua kỹthuật tạo mẫu khó và thay thếtừđồng nghĩa. Kết\nquảđạt được như sau:\n\n|Giá trị k|Độ chính xác|\n|---|---|\n|1<br>3<br>5|86.96%<br>89.68%<br>92.20%|\n\n\n\nBảng 4: Hiệu suất mô hình cải tiến trên tập dữliệu mởrộng\n\n\n**Phân tích kết quả**\n\n\nMô hình cải tiến cho thấy sựvượt trội rõ rệt ởmọi mức _k_ :\n\n\n - Với _k_ = 1: tăng từ **82.24%** lên **86.96%** ( **+4.72%** ). - ..."
        },
        {
          "idx": 9,
          "page": 1,
          "score": 0.8842895030975342,
          "text": "25\n\n6.5.4 Phân tích Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n6.6 Kết luận . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n\n\n1"
        },
        {
          "idx": 14,
          "page": 20,
          "score": 0.8878604173660278,
          "text": "**6.1** **Khung Phân loại Trọng sốĐềxuất**\n\n\nVì vậy nhóm đã nghiên cứu và đềxuất áp dụng công thức trọng sốmới trong quá trình voting của KNN\nbằng kết hợp hai yếu tốtương đồng (similarity) và tầm quan trọng tinh tếcủa từng thực thể(saliency). **6.2** **Công thức Cốt lõi**\n\n\nweight( _x_ _j_ _,_ _q_ ) = (1 _−_ _α_ ) _×_ similarity( _x_ _j_ _,_ _q_ ) _×_ ICF( _y_ ( _x_ _j_ )) + _α ×_ saliency( _x_ _j_ _,_ _q_ ) (5)\n\n\nTrong đó:\n\n\n_x_ _j_ _·_ _q_\nsimilarity( _x_ _j_ _, q_ ) = cos( _x_ _j_ _, q_ ) = (6)\n_∥x_ _j_ _∥× ∥q∥_\n\n\n\n_N_\nICF( _c_ _i_ ) =\n_M × n_ _i_\n\n\n\n(7)\n\n\n\nsaliency( _x_ _j_ _, q_ ) = _∥∇_ _x_ _j_ _L_ ( _f_ ( _x_ _j_ ) _,_ ˆ _y_ ) _∥_ 2 (8)\n\n_α ∈_ [0 _,_ 1] (tham sốcân bằng) (9)\n\n\n**6.3** **Quyết định Phân loại Cuối cùng**\n\n\n\nˆ\n_y_ = arg max\n_c_ _i_ _∈C_\n\n\n\n�\n\n_x_ _j_ _∈N_ _K_ ( _q_ )\n_y_ ( _x_ _j_ )= _c_ _i_\n\n\n20\n\n\n\nweight( _x_ _j_ _, q_ ) (10)"
        }
      ],
      "model_verdict": null
    },
    "13": {
      "supported_by_embeddings": true,
      "max_similarity": 0.8059824109077454,
      "evidence": [
        {
          "idx": 14,
          "page": 20,
          "score": 0.5798600316047668,
          "text": "**6.1** **Khung Phân loại Trọng sốĐềxuất**\n\n\nVì vậy nhóm đã nghiên cứu và đềxuất áp dụng công thức trọng sốmới trong quá trình voting của KNN\nbằng kết hợp hai yếu tốtương đồng (similarity) và tầm quan trọng tinh tếcủa từng thực thể(saliency). **6.2** **Công thức Cốt lõi**\n\n\nweight( _x_ _j_ _,_ _q_ ) = (1 _−_ _α_ ) _×_ similarity( _x_ _j_ _,_ _q_ ) _×_ ICF( _y_ ( _x_ _j_ )) + _α ×_ saliency( _x_ _j_ _,_ _q_ ) (5)\n\n\nTrong đó:\n\n\n_x_ _j_ _·_ _q_\nsimilarity( _x_ _j_ _, q_ ) = cos( _x_ _j_ _, q_ ) = (6)\n_∥x_ _j_ _∥× ∥q∥_\n\n\n\n_N_\nICF( _c_ _i_ ) =\n_M × n_ _i_\n\n\n\n(7)\n\n\n\nsaliency( _x_ _j_ _, q_ ) = _∥∇_ _x_ _j_ _L_ ( _f_ ( _x_ _j_ ) _,_ ˆ _y_ ) _∥_ 2 (8)\n\n_α ∈_ [0 _,_ 1] (tham sốcân bằng) (9)\n\n\n**6.3** **Quyết định Phân loại Cuối cùng**\n\n\n\nˆ\n_y_ = arg max\n_c_ _i_ _∈C_\n\n\n\n�\n\n_x_ _j_ _∈N_ _K_ ( _q_ )\n_y_ ( _x_ _j_ )= _c_ _i_\n\n\n20\n\n\n\nweight( _x_ _j_ _, q_ ) (10)"
        },
        {
          "idx": 18,
          "page": 7,
          "score": 0.7496178150177002,
          "text": "Tham số _α_ là tham sốđiều chỉnh, quyết định mức độưu tiên của điểm saliency so với độ\ntương đồng tổng thểcủa tin nhắn. - **Vote Scores:** Hệthống hiển thịđiểm sốbỏphiếu cho mỗi lớp ( _Ham_ và _Spam_ ). Dựđoán cuối\ncùng sẽlà lớp có điểm sốcao nhất. - **Spam Subcategory:** Nếu tin nhắn được phân loại là _SPAM_, hệthống tiếp tục phân tích đểxác\nđịnh tiểu mục spam cụthể(ví dụ: _spam_quangcao_, _spam_hethong_ ). **Cơ sởgiải thích (Top neighbors):** Hệthống liệt kê một sốhàng xóm gần nhất trong cơ sởdữ\nliệu vector. Mỗi neighbors bao gồm:\n\n\n**–** _Nhãn (Label):_ Nhãn của tin nhắn gốc ( _ham_ hoặc _spam_ ). **–**\n_Độtương đồng (Similarity):_ Giá trịthểhiện mức độtương đồng giữa tin nhắn đầu vào và\nhàng xóm. **–**\n_Nội dung (Message):_ Nội dung của tin nhắn hàng xóm. 7"
        },
        {
          "idx": 33,
          "page": 6,
          "score": 0.8059824109077454,
          "text": "**Similarity Search (KNN-Classifier):**\n\n\n **Vấn đềtồn đọng:** Phương pháp bỏphiếu đa số( _majority vote_ ) đơn giản trong KNN bỏqua\nmức độquan trọng của từng hàng xóm, nên các điểm ”xa” nhưng đông vẫn có thểáp đảo những\nđiểm ”gần” và ảnh hưởng sai lệch đến kết quảphân loại. **Giải pháp:** Khi có một tin nhắn mới, hệthống tìm kiếm những tin nhắn tương tựnhất. Quyết\nđịnh phân loại được đưa ra bằng Weighted KNN, sửdụng độtương đồng ( _similarity score_ ) làm\ntrọng sốđểưu tiên các hàng xóm gần hơn. 6"
        }
      ],
      "model_verdict": null
    },
    "14": {
      "supported_by_embeddings": true,
      "max_similarity": 1.1322075128555298,
      "evidence": [
        {
          "idx": 53,
          "page": 17,
          "score": 0.6295226812362671,
          "text": "**AI VIETNAM** **aivietnam.edu.vn**\n\n\n**Cấu trúc** BERT-base có **12 lớp encoder**, mỗi lớp bao gồm:\n\n\n1. **Multi-Head Self-Attention** : Cho phép mỗi token “chú ý” đến các token khác trong chuỗi để\ncập nhật vector của nó. Công thức:\n\n\n\n_QK_ _T_\nAttention( _Q, K, V_ ) = softmax\n� ~~_√_~~ _d_ _k_\n\n\n\n_V_\n�\n\n\n\n\n  - _Q_, _K_, _V_ : Ma trận query, key, value, được tạo từma trận embedding qua các trọng số _W_ _Q_,\n_W_ _K_, _W_ _V_ . - _d_ _k_ : Kích thước mỗi head (768 / 12 = 64). - Mỗi lớp có **12 head**, mỗi head xửlý một góc nhìn khác của ngữcảnh. Ví dụ: Trong “Nhận ngay quà tặng miễn phí!”, token “miễn” chú ý mạnh đến “quà” và “tặng”,\ntạo ngữcảnh quảng cáo. Attention Mask đảm bảo không chú ý đến [PAD]. Kết quả: Ma trận 16\n_×_ 768, với mỗi token được cập nhật dựa trên ngữcảnh. 2. **Residual Connection và Layer Normalization** : Cộng đầu vào và đầu ra của attention:\n\n\n_x_ + Attention( _x_ )\n\n\nSau đó chuẩn hóa:\nLayerNorm( _x_ + Attention( _x_ ))\n\n\n3. **Feed-Forward Neural Network (FFN)** : ..."
        },
        {
          "idx": 50,
          "page": 7,
          "score": 1.0809839963912964,
          "text": "**AI VIETNAM** **aivietnam.edu.vn**\n\n\n**Explainable AI (XAI) và Classifier:**\n\n\n **Vấn đềtồn đọng:** Mô hình hoạt động như một ”hộp đen”, khó giải thích lý do đưa ra dựđoán. Khảnăng giải thích thường bịtách rời khỏi quá trình phân loại chính. **Giải pháp:** Tích hợp khảnăng giải thích vào lõi của bộphân loại. **–**\n_Masking-based Saliency:_ Phương pháp này xác định các từkhóa quan trọng nhất trong tin\nnhắn. Nói trực quan thì từnào quan trọng trong quyết định spam hơn sẽđược tô đậm hơn. **–**\n_Phân loại có tích hợp Saliency:_ Bộphân loại sửdụng một tham số‘alpha‘ đểđiều chỉnh mức\nđộảnh hưởng của điểm nổi bật (saliency score) vào công thức phân loại cuối cùng, giúp kết\nquảchính xác hơn và có thểgiải thích được. **Đầu ra cuối cùng:** Đầu ra cho mỗi câu gồm thông tin dựđoán và chỉsốgiải thích cho dựđoán đó,\ngiúp người dùng hiểu rõ quyết định của mô hình. Cấu trúc đầu ra bao gồm:\n\n\n - **Lớp dựđoán:** Tin nhắn được gán nhãn dựđoán cuối cùng ( _SPAM_ hoặc _HAM_ ) dựa trên kết quả\nphân loại. *..."
        },
        {
          "idx": 54,
          "page": 22,
          "score": 1.1322075128555298,
          "text": "Lấy ví dụđơn giản, giảsửchúng ta có một mã là một chuỗi nhịphân độdài 5, chẳng hạn như “ `10001` ”. Khi đó, lượng tin của mã này sẽlà 5 bit. Hình 3: Minh họa mối quan hệgiữa nội dung thông tin và tần suất lớp\n\n\nTừlý thuyết thông tin, nội dung thông tin của lớp _c_ _i_ là:\n\n\n\n_n_ _i_\n_I_ ( _c_ _i_ ) = _−_ log 2 ( _P_ ( _c_ _i_ )) = _−_ log 2\n� _N_\n\n\n\n(20)\n�\n\n\n\nICF của chúng ta tỷlệthuận với 2 _[I]_ [(] _[c]_ _[i]_ [)/][ log] [2] [(] _[N]_ [/] _[M]_ [)], có nghĩa là **các lớp hiếm hơn mang nhiều thông**\n**tin hơn** và nên nhận được trọng sốtỷlệcao hơn. **6.4.2** **Trọng sốKhoảng cách dựa trên Similarity**\n\n\n**Định nghĩa 2** (Cosine Similarity Kernel) **.** _Thành phần similarity đảm bảo rằng_ _**láng giềng gần hơn**_\n_**có ảnh hưởng mạnh hơn**_ _:_\n\n\n_x_ _j_ _·_ _q_\n_K_ cos ( _x_ _j_ _, q_ ) = cos( _x_ _j_ _, q_ ) = (21)\n_∥x_ _j_ _∥× ∥q∥_\n\n\n**Mệnh đề2** (Tính chất Kernel) **.** _K_ cos _là một Mercer kernel hợp lệthỏa mãn dựa trên nghiên cứu Ghojogh,_\n_B., Ghodsi, A., Karray, F., & Crowl..."
        }
      ],
      "model_verdict": null
    },
    "15": {
      "supported_by_embeddings": true,
      "max_similarity": 0.9300246834754944,
      "evidence": [
        {
          "idx": 3,
          "page": 28,
          "score": 0.746843695640564,
          "text": "**–**\nNhờđó, mô hình có thểhiểu được sựkhác biệt tinh tếgiữa các cách diễn đạt, xửlý được\ncác từđồng nghĩa và các biến thểngôn ngữ. **Nhược điểm:**\n\n\n**– Đòi hỏi tài nguyên tính toán lớn:** Việc huấn luyện và fine-tuning các mô hình này cần\nnhiều thời gian và chi phí. **– Phức tạp:** Việc fine-tuning cho từng tác vụcụthểcó thểphức tạp. Đặc biệt, nếu không có\nđủdữliệu đã được gán nhãn, hiệu quảcủa các mô hình này sẽbịhạn chế. **7.3** **Phương pháp Semi-supervised sub-category của spam**\n\n\nĐểtận dụng ưu điểm của 2 phương pháp phân loại sub-category phần trên. Chúng tôi đềxuất thực\nhiện một phương pháp semi-supervised bằng cách kết hợp bert embeđings với nối từkhóa. Phương pháp này được gọi là ”bán giám sát” vì nó sửdụng một lượng nhỏdữliệu có nhãn (reference_texts\nvà category_keywords) đểphân loại một lượng lớn dữliệu chưa có nhãn (spam_texts). Tiến trình thực hiện của phương pháp như sau:\n\n\n1. **Bước 1: BERT embeddings**\n\n\n  **Tạo Embeddings của Văn bản Spam:** đểbiến mỗi tin nhắn spam ..."
        },
        {
          "idx": 2,
          "page": 15,
          "score": 0.8782092928886414,
          "text": "**AI VIETNAM** **aivietnam.edu.vn**\n\n\nmua, thanh toán,.... **Bi-directional (hai chiều):** Ngữnghĩa của một từkhông chỉđược biểu diễn bởi những từliền trước\nmà còn được giải thích bởi toàn bộcác từxung quanh. Luồng giải thích tuân theo đồng thời từtrái\nqua phải và từphải qua trái cùng một lúc. Đại diện cho các phép biểu diễn từnày là những mô hình\nsửdụng kỹthuật transformer ví dụnhư BERT. **5.2** **BERT là gì?**\n\n\nBERT (Bidirectional Encoder Representations from Transformers) là một mô hình học sâu tiên tiến do\nGoogle phát triển, nổi bật với khảnăng hiểu ngữcảnh ngôn ngữtựnhiên theo hai chiều. Trong bài toán\nphân loại tin nhắn spam/ham, BERT chuyển đổi tin nhắn thành biểu diễn số, nắm bắt ngữcảnh sâu sắc,\nvà dựđoán nhãn (spam hoặc ham) với độchính xác cao. Kiến trúc BERT-base gồm **12 lớp encoder**\n**Transformer**, mỗi lớp có **768 chiều ẩn** (hidden size) và **12 head attention**, với tổng cộng khoảng\n**110 triệu tham số** . Mô hình được huấn luyện trước trên dữliệu lớn (Wikipedia, Bo..."
        },
        {
          "idx": 16,
          "page": 13,
          "score": 0.9300246834754944,
          "text": "Nếu có thêm thời gian, nhóm sẽmởrộng phương pháp này đểgiải thích cho cảcác câu được\nphân loại là ham, tuy nhiên cách làm sẽhoàn toàn tương tự. **Ý tưởng thuật toán:** Đầu tiên, ta tính `spam_scores` ban đầu — là tổng điểm tương đồng giữa\nembedding của câu đầu vào với các láng giềng có nhãn “spam” trong tập huấn luyện. Sau đó, ta đo\nmức độgiảm điểm `spam_scores` khi lần lượt che từng token, theo các bước sau:\n\n\n13"
        }
      ],
      "model_verdict": null
    },
    "16": {
      "supported_by_embeddings": true,
      "max_similarity": 1.2162450551986694,
      "evidence": [
        {
          "idx": 46,
          "page": 11,
          "score": 0.9961504340171814,
          "text": "**Xây dựng tập cụm ngữnghĩa theo chủđề** : Các nhóm cụm từđược phân loại theo 7 chủđề\ndễgây nhầm lẫn giữa spam và ham, bao gồm:\n\n\n  - `financial_phrases` (liên quan đến giao dịch, tiền bạc)\n\n\n  - `promotion_phrases` (quảng cáo, ưu đãi)\n\n  - `lottery_phrases` (trúng thưởng, phần thưởng)\n\n\n  - `scam_alert_phrases` (cảnh báo giảmạo)\n\n\n  - `call_to_action_phrases` (dẫn dụngười dùng hành động)\n\n\n  - `social_engineering_phrases` (lừa đảo cảm xúc)\n\n  - `obfuscated_phrases` (che giấu, tránh bộlọc spam)\n\n\n2. **Sinh dữliệu bằng kịch bản và LLM** :\n\n\n    - Với mỗi nhóm cụm từ, nhóm thiết kếmột tập các kịch bản “base” như: _“Hey, did you hear_\n_about...”_, _“Bro, you should check this out”_ ... - Các cụm spam hoặc ham tương ứng được **chèn vào base**, tạo ra các mẫu dữliệu mới, theo\ncấu trúc _“base + insert”_ hoặc _“insert + base”_ . - Ngoài ra, nhóm chúng mình sửdụng LLM (như GPT hoặc Mixtral) đểsinh các câu mới theo\ntemplate kịch bản thực tế, nhằm tái hiện các loại spam ngụy trang phổbiến."
        },
        {
          "idx": 66,
          "page": 3,
          "score": 1.1186320781707764,
          "text": "**Email Spam là gì?**\n\n\n\n\n\n**Ví dụ(Spam Email):**\n\n\n _“Win a brand new iPhone today! Just click this link to claim!”_\n\n\n _“You’ve been selected for a $1000 Walmart gift card!”_\n\n\n _“Invest in crypto now and double your money overnight!”_\n\n\n**Email Ham là gì?**\n\n\n\n\n\n**Ví dụ(Ham Email):**\n\n\n _“Hi John, just a reminder that your doctor’s appointment is at 3PM today.”_\n\n\n _“Your monthly salary has been transferred to your account.”_\n\n\n _“Please review the attached report before the meeting tomorrow.”_\n\n\n3"
        },
        {
          "idx": 26,
          "page": 14,
          "score": 1.2162450551986694,
          "text": "Các kết quảbiểu diễn từđã\ncó bối cảnh nhưng chỉđược giải thích bởi một chiều từtrái qua phải hoặc từphải qua trái. VD:\n\n\n**Câu C:** Hôm nay tôi mang 200 tỷ[gửi] ởngân hàng. **Câu D:** Hôm nay tôi mang 200 tỷ[gửi] …. Như vậy véc tơ biểu diễn của từ **gửi** được xác định thông qua các từliền trước với nó. Nếu chỉdựa vào\ncác từliền trước Hôm nay tôi mang 200 tỷthì ta có thểnghĩ từphù hợp ởvịtrí hiện tại là cho vay,\n\n\n14"
        }
      ],
      "model_verdict": null
    },
    "17": {
      "supported_by_embeddings": true,
      "max_similarity": 0.6036962270736694,
      "evidence": [
        {
          "idx": 21,
          "page": 15,
          "score": 0.5917988419532776,
          "text": "Trong bài toán spam/ham, BERT được tinh\nchỉnh đểtối ưu hóa dựđoán nhãn và tập trung vào các từkhóa quan trọng như “miễn phí” hoặc “quà\ntặng” trong tin nhắn spam. **Ứng dụng** : Trong phân loại tin nhắn spam/ham, BERT chuyển tin nhắn thành vector số, hiểu ngữ\ncảnh sâu sắc (ví dụ: nhận diện ”miễn phí” trong ngữcảnh quảng cáo), và dựđoán nhãn (spam hoặc\nham). **Ưu điểm** :\n\n\n  - Hiểu ngữcảnh hai chiều, vượt trội so với các phương pháp truyền thống như TF-IDF. - Sửdụng vector [CLS] đểtổng hợp thông tin toàn câu, phù hợp cho phân loại. **5.3** **Kiến trúc BERT**\n\n\nQuy trình xửlý của BERT bao gồm ba giai đoạn chính:\n\n\n1. **Mã hóa đầu vào** : Chuyển tin nhắn thành token, embedding, và attention mask. 2. **Xửlý qua Transformer encoder** : Tạo biểu diễn ngữcảnh cho từng token, đặc biệt là vector\n\n[CLS]. 3. **Phân loại** : Sửdụng vector [CLS] đểdựđoán nhãn spam/ham. Phần này trình bày chi tiết từng thành phần của kiến trúc BERT và cách chúng hỗtrợbài toán phân\nloại tin nhắn spam/ham. **5.3.1** *..."
        },
        {
          "idx": 1,
          "page": 5,
          "score": 0.6036962270736694,
          "text": "Điều này đặc biệt quan trọng\ntrong các hệthống chống spam hiện đại, giúp người dùng hiểu rõ liệu một email nên bịxóa, xem qua\nhay báo cáo. Ngoài ra, nhóm còn hướng đến việc **mởrộng phân loại chi tiết trong nhóm spam**\n(quảng cáo, hệthống, lừa đảo, v.v...) nhằm tăng trải nghiệm và bảo mật cho người dùng. Hệthống phân loại tin nhắn spam/ham được thiết kếvới cơ chếđầu vào – đầu ra như sau:\n\n\n\n\n\n5"
        }
      ],
      "model_verdict": null
    },
    "18": {
      "supported_by_embeddings": true,
      "max_similarity": 0.974981427192688,
      "evidence": [
        {
          "idx": 3,
          "page": 28,
          "score": 0.5795202255249023,
          "text": "**–**\nNhờđó, mô hình có thểhiểu được sựkhác biệt tinh tếgiữa các cách diễn đạt, xửlý được\ncác từđồng nghĩa và các biến thểngôn ngữ. **Nhược điểm:**\n\n\n**– Đòi hỏi tài nguyên tính toán lớn:** Việc huấn luyện và fine-tuning các mô hình này cần\nnhiều thời gian và chi phí. **– Phức tạp:** Việc fine-tuning cho từng tác vụcụthểcó thểphức tạp. Đặc biệt, nếu không có\nđủdữliệu đã được gán nhãn, hiệu quảcủa các mô hình này sẽbịhạn chế. **7.3** **Phương pháp Semi-supervised sub-category của spam**\n\n\nĐểtận dụng ưu điểm của 2 phương pháp phân loại sub-category phần trên. Chúng tôi đềxuất thực\nhiện một phương pháp semi-supervised bằng cách kết hợp bert embeđings với nối từkhóa. Phương pháp này được gọi là ”bán giám sát” vì nó sửdụng một lượng nhỏdữliệu có nhãn (reference_texts\nvà category_keywords) đểphân loại một lượng lớn dữliệu chưa có nhãn (spam_texts). Tiến trình thực hiện của phương pháp như sau:\n\n\n1. **Bước 1: BERT embeddings**\n\n\n  **Tạo Embeddings của Văn bản Spam:** đểbiến mỗi tin nhắn spam ..."
        },
        {
          "idx": 61,
          "page": 26,
          "score": 0.8431670665740967,
          "text": "Những cải thiện này đến từcác yếu tốsau:\n\n\n **Tăng cường dữliệu:** sinh thêm mẫu khó và thay từđồng nghĩa giúp đa dạng hóa ngữcảnh và\nlàm mô hình học được ranh giới phân biệt tốt hơn. **Tập huấn luyện lớn hơn:** từdưới 1.000 mẫu lên hơn 9.000 mẫu giúp mô hình tổng quát hóa\ntốt hơn. **Tập trung vào mẫu khó:** ưu tiên những ví dụgần ranh giới giữa spam/ham nhằm tăng tính\nphân biệt cho mô hình. **Kết luận:** Mô hình mới không chỉđạt hiệu suất cao ở _k_ = 5 mà còn cải thiện đáng kểở _k_ = 1, rất hữu\ních cho các ứng dụng yêu cầu tốc độsuy luận nhanh mà vẫn đảm bảo độchính xác cao. 26"
        },
        {
          "idx": 13,
          "page": 14,
          "score": 0.974981427192688,
          "text": "Hiệu quảbiểu thịnội dung và truyền đạt ý nghĩa sẽlớn hơn so với từng từđứng độc lập. Ngữcảnh trong câu có một sựảnh hưởng rất lớn trong việc giải thích ý nghĩa của từ. Hiểu được vai\ntrò mấu chốt đó, các thuật toán NLP SOTA đều cốgắng đưa ngữcảnh vào mô hình nhằm tạo ra sự\nđột phá, giúp mô hình học được thông tin chính xác hơn. Phân cấp mức độphát triển của các phương pháp embedding từtrong NLP có thểbao gồm các nhóm:\n\n\n**Non-context (không bối cảnh):** Là các thuật toán không tồn tại bối cảnh trong biểu diễn từ. Đó là\ncác thuật toán NLP đời đầu như ‘ word2vec, GLoVe, fasttext‘. Chúng ta chỉcó duy nhất một biểu diễn\nvéc tơ cho mỗi một từmà không thay đổi theo bối cảnh. VD:\n\n\n**Câu A:** Cánh [đồng] này sắp được thu hoạch. **Câu B:** Tôi [đồng] ý với ý kiến của anh! Thì từ **đồng** sẽmang 2 ý nghĩa khác nhau nên phải có hai biểu diễn từriêng biệt. Các thuật toán\nnon-context không đáp ứng được sựđa dạng vềngữnghĩa của từtrong NLP. **Uni-directional (một chiều):** Là các thuật toán đã bắt đ..."
        }
      ],
      "model_verdict": null
    },
    "19": {
      "supported_by_embeddings": true,
      "max_similarity": 0.7636357545852661,
      "evidence": [
        {
          "idx": 14,
          "page": 20,
          "score": 0.6900026798248291,
          "text": "**6.1** **Khung Phân loại Trọng sốĐềxuất**\n\n\nVì vậy nhóm đã nghiên cứu và đềxuất áp dụng công thức trọng sốmới trong quá trình voting của KNN\nbằng kết hợp hai yếu tốtương đồng (similarity) và tầm quan trọng tinh tếcủa từng thực thể(saliency). **6.2** **Công thức Cốt lõi**\n\n\nweight( _x_ _j_ _,_ _q_ ) = (1 _−_ _α_ ) _×_ similarity( _x_ _j_ _,_ _q_ ) _×_ ICF( _y_ ( _x_ _j_ )) + _α ×_ saliency( _x_ _j_ _,_ _q_ ) (5)\n\n\nTrong đó:\n\n\n_x_ _j_ _·_ _q_\nsimilarity( _x_ _j_ _, q_ ) = cos( _x_ _j_ _, q_ ) = (6)\n_∥x_ _j_ _∥× ∥q∥_\n\n\n\n_N_\nICF( _c_ _i_ ) =\n_M × n_ _i_\n\n\n\n(7)\n\n\n\nsaliency( _x_ _j_ _, q_ ) = _∥∇_ _x_ _j_ _L_ ( _f_ ( _x_ _j_ ) _,_ ˆ _y_ ) _∥_ 2 (8)\n\n_α ∈_ [0 _,_ 1] (tham sốcân bằng) (9)\n\n\n**6.3** **Quyết định Phân loại Cuối cùng**\n\n\n\nˆ\n_y_ = arg max\n_c_ _i_ _∈C_\n\n\n\n�\n\n_x_ _j_ _∈N_ _K_ ( _q_ )\n_y_ ( _x_ _j_ )= _c_ _i_\n\n\n20\n\n\n\nweight( _x_ _j_ _, q_ ) (10)"
        },
        {
          "idx": 0,
          "page": 19,
          "score": 0.7097625732421875,
          "text": "**AI VIETNAM** **aivietnam.edu.vn**\n\n## **6 KNN with Weight Voting**\n\n\n**1.6.1 Vấn đềMất cân bằng Lớp trong K-Nearest Neighbors**\n\n\nPhân phối lớp mất cân bằng đại diện cho cảthách thức lý thuyết và thực tiễn trong phân loại KNearest Neighbors, được tài liệu hóa rộng rãi trong văn hệmáy học (A survey on imbalanced learning:\nlatest research, applications and future directions: https://link.springer.com/article/10.1007/s10462024-10759-6). Vấn đềnày trởnên đặc biệt nghiêm trọng trong các lĩnh vực có phân phối lớp bịlệch tự\nnhiên, chẳng hạn như phát hiện gian lận (giao dịch gian lận _∼_ 0 _._ 1%), sàng lọc y tế(tỷlệmắc bệnh\n_∼_ 1 _−_ 5%), và lọc thư rác (tỷlệspam _∼_ 10 _−_ 40%). Vấn đềcơ bản xuất phát từviệc KNN dựa vào **majority voting**, hệthống ưu tiên lớp chiếm ưu thế\nbất kểmức độliên quan ngữnghĩa của từng láng giềng. Hình 2: Enter Caption\n\n\n**1.7.1 Hạn chếcủa Majority Voting trong Môi trường Mất cân bằng**\n\n\n**1.7.1.1 Phân tích Toán học vềBias của Majority Voting**\n\n\nGọi _C_ = _{c_ ..."
        },
        {
          "idx": 33,
          "page": 6,
          "score": 0.7636357545852661,
          "text": "**Similarity Search (KNN-Classifier):**\n\n\n **Vấn đềtồn đọng:** Phương pháp bỏphiếu đa số( _majority vote_ ) đơn giản trong KNN bỏqua\nmức độquan trọng của từng hàng xóm, nên các điểm ”xa” nhưng đông vẫn có thểáp đảo những\nđiểm ”gần” và ảnh hưởng sai lệch đến kết quảphân loại. **Giải pháp:** Khi có một tin nhắn mới, hệthống tìm kiếm những tin nhắn tương tựnhất. Quyết\nđịnh phân loại được đưa ra bằng Weighted KNN, sửdụng độtương đồng ( _similarity score_ ) làm\ntrọng sốđểưu tiên các hàng xóm gần hơn. 6"
        }
      ],
      "model_verdict": null
    },
    "20": {
      "supported_by_embeddings": true,
      "max_similarity": 1.0194404125213623,
      "evidence": [
        {
          "idx": 41,
          "page": 19,
          "score": 0.8875085115432739,
          "text": "Đối với điểm truy vấn _q_, KNN truyền thống tính toán:\n\n\nˆ\n_y_ = arg max _c_ _i_ _∈C_ _[|{][x]_ _[j]_ _[ ∈N]_ _[K]_ [(] _[q]_ [) :] _[ y]_ [(] _[x]_ _[j]_ [) =] _[ c]_ _[i]_ _[}|]_ (1)\n\n\n**Phân tích Bias:**\nXác suất đểmột K-neighborhood ngẫu nhiên chứa _k_ thực thểtừlớp _c_ _i_ tuân theo phân phối siêu hình\nhọc:\n\n\n19"
        },
        {
          "idx": 28,
          "page": 16,
          "score": 1.0129456520080566,
          "text": "**Position Embedding** : Biểu diễn vịtrí của token (0, 1, 2, ...) đểgiữthông tin thứtự(Trong\nBERT, Position Embedding không sửdụng hàm sin/cosin như Transformer gốc, mà là các\nvector học được (learned embeddings)). **Segment Embedding** : Phân biệt các câu (thường là 0 cho một tin nhắn). Ví dụ: Token “miễn” ởvịtrí 5:\n\n\n   - Token Embedding: `[0.2, 0.1, ..., 0.3]` (768 chiều). - Position Embedding: `[0.01, -0.02, ..., 0.1]` (vịtrí 5). - Segment Embedding: `[0, 0, ..., 0]` (một câu). - Tổng embedding: `[0.21, 0.08, ..., 0.4]` (768 chiều). Kết quả: Ma trận embedding **16** _×_ **768** (16 token _×_ 768 chiều). 4. **Attention Mask** : Vector nhịphân chỉđịnh token nào được xửlý (1 cho token thực, 0 cho [PAD]). Ví dụ: `[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ..., 0]` (9 token thực, 7 [PAD]). **Liên hệvới spam/ham** Mã hóa đầu vào đảm bảo tin nhắn như “Nhận ngay quà tặng miễn phí!”\nđược chuyển thành ma trận số, với token [CLS] đóng vai trò tổng hợp ngữcảnh (như đặc trưng quảng\ncáo của “miễn phí”) đểhỗ..."
        },
        {
          "idx": 18,
          "page": 7,
          "score": 1.0194404125213623,
          "text": "Tham số _α_ là tham sốđiều chỉnh, quyết định mức độưu tiên của điểm saliency so với độ\ntương đồng tổng thểcủa tin nhắn. - **Vote Scores:** Hệthống hiển thịđiểm sốbỏphiếu cho mỗi lớp ( _Ham_ và _Spam_ ). Dựđoán cuối\ncùng sẽlà lớp có điểm sốcao nhất. - **Spam Subcategory:** Nếu tin nhắn được phân loại là _SPAM_, hệthống tiếp tục phân tích đểxác\nđịnh tiểu mục spam cụthể(ví dụ: _spam_quangcao_, _spam_hethong_ ). **Cơ sởgiải thích (Top neighbors):** Hệthống liệt kê một sốhàng xóm gần nhất trong cơ sởdữ\nliệu vector. Mỗi neighbors bao gồm:\n\n\n**–** _Nhãn (Label):_ Nhãn của tin nhắn gốc ( _ham_ hoặc _spam_ ). **–**\n_Độtương đồng (Similarity):_ Giá trịthểhiện mức độtương đồng giữa tin nhắn đầu vào và\nhàng xóm. **–**\n_Nội dung (Message):_ Nội dung của tin nhắn hàng xóm. 7"
        }
      ],
      "model_verdict": null
    }
  }
}